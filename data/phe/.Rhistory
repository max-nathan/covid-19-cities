View(df)
View(df)
df <- subset(df, !x=="2016")
View(df)
df <- subset(df, !x=="2016" | !x=="2009" | !x=="2007" | !x=="2030")
df <- subset(df, !x=="2009")
df <- subset(df, !x=="2007")
df <- subset(df, !x=="2030")
df <- subset(df, !x=="2016" & !x=="2009" & !x=="2007" & !x=="2030" & !x=="9999" )
View(df)
df <- subset(df, !x=="2016" & !x=="2009" & !x=="2007" & !x=="2030" & !x=="9999"
& !x=="2005" & !x=="2012" & !x=="2018" & !x=="2010")
df <- subset(df, !x=="2016" & !x=="2009" & !x=="2007" & !x=="2030" & !x=="9999"
& !x=="2005" & !x=="2012" & !x=="2018" & !x=="2010" & !x=="2015" & !x=="2019")
df <- subset(df, !x=="2016" & !x=="2009" & !x=="2007" & !x=="2030"
& !x=="9999" & !x=="2005" & !x=="2012" & !x=="2018"
& !x=="2010" & !x=="2015" & !x=="2019" & !x=="2017")
df <- subset(df, !x=="2016" & !x=="2009" & !x=="2007" & !x=="2030"
& !x=="9999" & !x=="2005" & !x=="2012" & !x=="2018" & !x=="2008"
& !x=="2010" & !x=="2015" & !x=="2019" & !x=="2017" & !x=="2011")
df <- subset(df, !x=="2016" & !x=="2009" & !x=="2007" & !x=="2030"
& !x=="9999" & !x=="2005" & !x=="2012" & !x=="2018" & !x=="2008"
& !x=="2010" & !x=="2015" & !x=="2019" & !x=="2017" & !x=="2011" & !x=="2020")
# pull out individual json fields and compile into R objects
id_f <- function(x) {as.list(x$properties$id)}
id <- as.list(plyr::llply(tfl_in$features,id_f))
id <- rbindlist(id)
name_f <- function(x) {as.list(x$properties$name)}
name <- as.list(plyr::llply(tfl_in$features,name_f))
name <- rbindlist(name)
ll_f <- function(x) {as.list(x$geometry$coordinates)}
ll <- as.list(plyr::llply(tfl_in$features,ll_f))
ll <- rbindlist(ll)
# libraries
require(jsonlite)
require(RJSONIO)
require(data.table)
require(plyr)
# import json object
tfl_stations <- '~/DataShare/projects/03_Working/P06_tech_city_impact/data/tfl_stations.json'
tfl_in <- fromJSON(tfl_stations, flatten = TRUE, method = C, simplifyVector = TRUE,
simplifyDataFrame = simplifyVector, simplifyMatrix = simplifyVector)
# look at json
object.size(tfl_in)
names(tfl_in)
# pull out individual json fields and compile into R objects
id_f <- function(x) {as.list(x$properties$id)}
id <- as.list(plyr::llply(tfl_in$features,id_f))
id <- rbindlist(id)
name_f <- function(x) {as.list(x$properties$name)}
name <- as.list(plyr::llply(tfl_in$features,name_f))
name <- rbindlist(name)
ll_f <- function(x) {as.list(x$geometry$coordinates)}
ll <- as.list(plyr::llply(tfl_in$features,ll_f))
ll <- rbindlist(ll)
# .... not working properly
# ... apply some function to extract columns from $properties$lines array
lines_f <- function(x) {as.list(x$properties$lines)}
x <- as.list(plyr::llply(tfl_in$features,lines_f))
xxx <- unlist(lapply(lines, '[[', 1)) # this pulls out $name but also $nightopened
lines <- as.data.frame(x)
lines <- subset(df, !x=="2016" & !x=="2009" & !x=="2007" & !x=="2030" & !x=="9999"
& !x=="2005" & !x=="2012" & !x=="2018" & !x=="2008" & !x=="2010"
& !x=="2015" & !x=="2019" & !x=="2017" & !x=="2011" & !x=="2020")
# compile R objects into a dataframe and export as CSV
tfl_out <- setnames(cbind(id, name, ll, lines), c("id","name","longitude","latitude", "line"))  [order(id)]
lines_f <- function(x) {as.list(x$properties$lines)}
x <- as.list(plyr::llply(tfl_in$features,lines_f))
xx <- unlist(lapply(lines, '[[', 1)) # this pulls out $name but also $nightopened
lines <- as.data.frame(xx)
lines <- subset(df, !x=="2016" & !x=="2009" & !x=="2007" & !x=="2030" & !x=="9999"
& !x=="2005" & !x=="2012" & !x=="2018" & !x=="2008" & !x=="2010"
& !x=="2015" & !x=="2019" & !x=="2017" & !x=="2011" & !x=="2020")
lines_f <- function(x) {as.list(x$properties$lines)}
lines <- as.list(plyr::llply(tfl_in$features,lines_f))
x <- unlist(lapply(lines, '[[', 1)) # this pulls out $name but also $nightopened
df <- as.data.frame(x)
df <- subset(df, !x=="2016" & !x=="2009" & !x=="2007" & !x=="2030" & !x=="9999"
& !x=="2005" & !x=="2012" & !x=="2018" & !x=="2008" & !x=="2010"
& !x=="2015" & !x=="2019" & !x=="2017" & !x=="2011" & !x=="2020")
tfl_out <- setnames(cbind(id, name, ll, df), c("id","name","longitude","latitude", "line"))  [order(id)]
View(df)
write.csv(tfl_out,"~/DataShare/projects/03_Working/P06_tech_city_impact/data/tfl_stations_out_test.csv",row.names=FALSE)
parts <- strsplit(names(lines), '-')
years <- sapply(parts, function(x) x[1])
pres <-  sapply(parts, function(x) x[2])
years <- sapply(lines, function(x) x[1])
pres <-  sapply(parts, function(x) x[2])
object1 <- sapply(lines, function(x) x[1])
object2 <-  sapply(lines, function(x) x[2])
x <- unlist(lapply(object1, '[[', 1))
df <- as.data.frame(x)
View(df)
y <- unlist(lapply(object1, '[[', 2))
# libraries
require(jsonlite)
require(RJSONIO)
require(data.table)
require(plyr)
# import json object
tfl_stations <- '~/DataShare/projects/03_Working/P06_tech_city_impact/data/tfl_stations.json'
tfl_in <- fromJSON(tfl_stations, flatten = TRUE, method = C, simplifyVector = TRUE,
simplifyDataFrame = simplifyVector, simplifyMatrix = simplifyVector)
lines_f <- function(x) {as.list(x$properties$lines)}
lines <- as.list(plyr::llply(tfl_in$features,lines_f))
x <- sapply(lines, function(x) x[1])
x <- unlist(lapply(object1, '[[', 1))
df <- as.data.frame(x)
x <- unlist(lapply(x, '[[', 1))
df <- as.data.frame(x)
y <- sapply(strsplit(lines, "\\s+"), head, n=2)
object2 <-  sapply(lines, function(x) x[2])
line2 <- object2$name
tfl_out <- setnames(cbind(id, name, ll, df), c("id","name","longitude","latitude", "line"))  [order(id)]
# libraries
require(jsonlite)
require(RJSONIO)
require(data.table)
require(plyr)
# import json object
tfl_stations <- '~/DataShare/projects/03_Working/P06_tech_city_impact/data/tfl_stations.json'
tfl_in <- fromJSON(tfl_stations, flatten = TRUE, method = C, simplifyVector = TRUE,
simplifyDataFrame = simplifyVector, simplifyMatrix = simplifyVector)
# look at json
object.size(tfl_in)
names(tfl_in)
# pull out individual json fields and compile into R objects
# lines function only pulls out first tube line for the station
id_f <- function(x) {as.list(x$properties$id)}
id <- as.list(plyr::llply(tfl_in$features,id_f))
id <- rbindlist(id)
name_f <- function(x) {as.list(x$properties$name)}
name <- as.list(plyr::llply(tfl_in$features,name_f))
name <- rbindlist(name)
ll_f <- function(x) {as.list(x$geometry$coordinates)}
ll <- as.list(plyr::llply(tfl_in$features,ll_f))
ll <- rbindlist(ll)
lines_f <- function(x) {as.list(x$properties$lines)}
lines <- as.list(plyr::llply(tfl_in$features,lines_f))
x <- sapply(lines, function(x) x[1])
x <- unlist(lapply(x, '[[', 1))
df <- as.data.frame(x)
tfl_out <- setnames(cbind(id, name, ll, df), c("id","name","longitude","latitude", "line"))  [order(id)]
tfl_out <- subset(tfl_out, !xline=="Crossrail")
tfl_out <- subset(tfl_out, !line=="Crossrail")
View(tfl_out)
tfl_out <- subset(tfl_out, !line=="Crossrail" & !line=="Crossrail 2")
View(tfl_out)
write.csv(tfl_out,"~/DataShare/projects/03_Working/P06_tech_city_impact/data/tfl_stations_out.csv",row.names=FALSE)
require(jsonlite)
require(RJSONIO)
require(data.table)
require(plyr)
install.packages(devtools)
install.packages("devtools")
devtools::install_github("dreamRs/esquisse")
x <- read.csv(file = "/Users/nathanm/Dropbox/DB_data/oc_extended/companies.csv", sep = ",")
x <- read.csv(file = "/Users/Max/Dropbox/DB_data/oc_extended/companies.csv", sep = ",")
x <- read.csv(file = "/Users/Max/Dropbox/DB_data/oc_extended/companies.csv", sep = ",")[ ,c('company_number')]
install.packages("janitor")
plot(cars)
library(rvest)
m100 <- read_html("http://en.wikipedia.org/wiki/Men%27s_100_metres_world_record_progression")
m100
rvest::read_html("http://en.wikipedia.org/wiki/Men%27s_100_metres_world_record_progression")
rvest:read_html("http://en.wikipedia.org/wiki/Men%27s_100_metres_world_record_progression")
rvest::read_html("http://en.wikipedia.org/wiki/Men%27s_100_metres_world_record_progression")
m100 <- read_html("http://en.wikipedia.org/wiki/Men%27s_100_metres_world_record_progression")
m100
m100 %>%
html_nodes("#mw-content-text > div > table:nth-child(8)") %>%
html_table (fill=T)
pre_iaaf =
m100 %>%
html_nodes("#mw-content-text > div > table:nth-child(8)") %>%
html_table (fill=T)
pre_iaaf
class(pre_iaaf)
library(tidyverse)
pre_iaaf =
pre_iaaf %>%
bind_rows() %>%
as_tibble()
pre_iaaf
class(pre_iaaf)
pre_iaaf =
pre_iaaf %>%
clean_names()
library(janitor)
pre_iaaf =
pre_iaaf %>%
clean_names()
pre_iaaf
pre_iaaf =
pre_iaaf %>%
mutate(athlete = ifelse(is.na(as.numeric(athlete)), athlete, lag(athlete)))
library(lubridate)
pre_iaaf =
pre_iaaf <%>
mutate(date = mdy(date))
pre_iaaf =
pre_iaaf <%>
mutate(date = mdy(date))
pre_iaaf =
pre_iaaf %>%
mutate(date = mdy(date))
pre_iaaf
ggplot(pre_iaaf)
ggplot(pre_iaaf, aes(date, time))
ggplot(pre_iaaf, aes(date, time) + geom_point())
ggplot(pre_iaaf, aes(date, time)) + geom_point()
pre_76 =
m100 %>%
html_nodes("#mw-content-text > div > table:nth-child(14") %>%
html_table (fill=T)
pre_76 =
m100 %>%
html_nodes("#mw-content-text > div > table:nth-child(14")) %>%
html_table (fill=T)
pre_76 =
m100 %>%
html_nodes("#mw-content-text > div > table:nth-child(14)") %>%
html_table (fill=T)
pre_76 =
pre_76 %>%
bind_rows() %>%
as_tibble()
pre_76
pre_76 =
pre_76 %>% clean_names() %>%
mutate(athlete = ifelse(athlete="", athlete, lag(athlete))) %>%
mutate(date = mdy(date))
pre_76 =
pre_76 %>% clean_names() %>%
mutate(athlete = ifelse(athlete=="", athlete, lag(athlete))) %>%
mutate(date = mdy(date))
tail(pre_76)
pre_76 %>% tail(30)
pre_76 %>% tail(20)
pre_iaff
pre_iaaf
wr =
bind_rows(
pre_iaaf %>% select(time, athelete, nationality:date) %>% mutate(era = "Pre-IAAF"),
pre_76 %>% select(time, athelete, nationality:date) %>% mutate(era = "Pre-automatic"),
)
wr =
bind_rows(
pre_iaaf %>% select(time, athlete, nationality:date) %>% mutate(era = "Pre-IAAF"),
pre_76 %>% select(time, athlete, nationality:date) %>% mutate(era = "Pre-automatic"),
)
wr
wr %>%
ggplot(aes(date, time)) +
geom_point +
labs(
title = "some title",
x = "date", y = "time",
caption = "source: wikipedia"
)
wr %>%
ggplot(aes(date, time)) +
geom_point() +
labs(
title = "some title",
x = "date", y = "time",
caption = "source: wikipedia"
)
wr %>%
ggplot(aes(date, time)) +
geom_point() +
labs(
title = "Men's 100m world record progression",
x = "date", y = "time",
caption = "source: wikipedia"
)
library(tidyverse)
library(jsonlite)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, dpi=300)
## Load and install the packages that we'll be using today
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, httr, lubridate, hrbrthemes, janitor, jsonlite, listviewer, usethis, fredr)
## My preferred ggplot2 plotting theme (optional)
## theme_set(hrbrthemes::theme_ipsum())
library(tidyverse)
library(jsonlite)
nyc_trees <-
fromJSON("https://data.cityofnewyork.us/resource/nwxe-4ae8.json") %>%
as_tibble()
nyc_trees
fromJSON("https://data.cityofnewyork.us/resource/nwxe-4ae8.json?$limit=5")
nyc_trees %>%
select(longitude, latitude, stump_diam, spc_common, spc_latin, tree_id) %>%
mutate_at(vars(longitude:stump_diam), as.numeric) %>%
ggplot(aes(x=longitude, y=latitude, size=stump_diam)) +
geom_point(alpha=0.5) +
scale_size_continuous(name = "Stump diameter") +
labs(
x = "Longitude", y = "Latitude",
title = "Sample of New York City trees",
caption = "Source: NYC Open Data"
)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, dpi=300)
nyc_trees %>%
select(longitude, latitude, stump_diam, spc_common, spc_latin, tree_id) %>%
mutate_at(vars(longitude:stump_diam), as.numeric) %>%
ggplot(aes(x=longitude, y=latitude, size=stump_diam)) +
geom_point(alpha=0.5) +
scale_size_continuous(name = "Stump diameter") +
labs(
x = "Longitude", y = "Latitude",
title = "Sample of New York City trees",
caption = "Source: NYC Open Data"
)
.libPaths()
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, httr, lubridate, hrbrthemes, janitor, jsonlite, listviewer, usethis, fredr)
.libPaths("~/Dropbox/code/R/library")
.libPaths()
.libPaths("~/Dropbox/code/R/library")
.libPaths()
getwd()
.libPaths("~/Dropbox/code/R/library")
.libPaths()
usethis::edit_r_environ()
readRenviron("~/.Renviron")
.libPaths()
library(tidyverse)
# set library path
.libPaths()
.libPaths("~/Dropbox/code/R/library")
.libPaths()
.libPaths("~/Dropbox/code/R/library_")
.libPaths()
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, httr, lubridate, hrbrthemes, janitor, jsonlite, listviewer, usethis, fredr)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, httr, lubridate, hrbrthemes, janitor, jsonlite, listviewer, usethis, fredr)
library(listviewer)
install.packages("listviewer")
library(hrbrthemes)
install.packages("hrbrthemes")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, httr, lubridate, hrbrthemes, janitor, jsonlite, listviewer, usethis, fredr)
pacman::p_load(tidyverse, httr, lubridate, hrbrthemes, janitor, jsonlite, listviewer, usethis, fredr)
install.packages("hrbrthemes")
library(hrbrthemes)
library(hrbrthemes, lib.loc = "/Library/Frameworks/R.framework/Versions/3.6/Resources/library")
hrbrthemes::import_roboto_condensed()
library(listviewer, lib.loc = "/Library/Frameworks/R.framework/Versions/3.6/Resources/library")
library(listviewer)
pacman::p_load(tidyverse, httr, lubridate, janitor, jsonlite, listviewer, usethis, fredr)
library(hrbrthemes)
library(markdown)
library(rmarkdown)
library(rmarkdown)
library(tidyverse)
library(rmarkdown, lib.loc = "~/Dropbox/code/R/library_")
.libPaths()
.libPaths("~/Dropbox/code/R/library_")
.libPaths()
library(tidyverse)
library(hrbrthemes)
library(hrbrthemes, lib.loc = "/Library/Frameworks/R.framework/Versions/3.6/Resources/library")
library(listviewer)
detach("package:listviewer", unload = TRUE)
remove.packages("listviewer", lib="~/Dropbox/code/R/library_")
library(listviewer, lib.loc = "/Library/Frameworks/R.framework/Versions/3.6/Resources/library")
install.packages("listviewer", lib="~/Dropbox/code/R/library_")
detach("package:listviewer", unload = TRUE)
install.packages("listviewer", lib="~/Dropbox/code/R/library_")
detach("package:hrbrthemes", unload = TRUE)
install.packages("hrbrthemes", lib="~/Dropbox/code/R/library_")
library(rmarkdown)
library(markdown)
remove.packages("markdown", lib="~/Dropbox/code/R/library_")
install.packages("markdown", lib="~/Dropbox/code/R/library_")
install.packages("markdown", lib = "~/Dropbox/code/R/library_")
detach("package:markdown", unload = TRUE)
library(tidyverse)
.libPaths("~/Dropbox/code/R/library_")
.libPaths()
pacman::p_load(tidyverse, httr, lubridate, janitor, jsonlite, listviewer, usethis, fredr)
library(pacman)
pacman::p_load(tidyverse, httr, lubridate, janitor, jsonlite, listviewer, usethis, fredr)
pacman::p_load(tidyverse, httr, hrbrthemes, lubridate, janitor, jsonlite, listviewer, usethis, fredr)
.libPaths("~/Dropbox/code/R/library_")
library(pacman)
pacman::p_load(tidyverse, httr, hrbrthemes, lubridate, janitor, jsonlite, listviewer, usethis, fredr)
.libPaths()
.libPaths("~/Dropbox/code/R/library_")
library(hrbrthemes)
library(tidyverse)
library(tidyverse)
library(rvest)
install.packages(c("BH", "broom", "callr", "caTools", "checkmate", "cli", "covr", "curl", "DBI", "digest", "dplyr", "DT", "dtplyr", "e1071", "english", "fansi", "farver", "gganimate", "gh", "hexbin", "Hmisc", "hms", "htmlTable", "ISOcodes", "knitr", "latticeExtra", "mapproj", "maptools", "mime", "mnormt", "multcomp", "mvtnorm", "ndjson", "openNLP", "pdftools", "pillar", "plyr", "prettyunits", "processx", "ps", "psych", "quantreg", "R6", "Rcpp", "RCurl", "RJSONIO", "rlang", "rmarkdown", "roxygen2", "rsconnect", "rstudioapi", "Rttf2pt1", "rversions", "scales", "selectr", "sf", "slam", "sp", "SparseM", "stringi", "svglite", "testthat", "tidyr", "tidyselect", "tinytex", "tm", "topicmodels", "TTR", "vctrs", "xaringan", "xfun", "XML", "xts", "yaml", "zoo"))
y
install.packages(c("BH", "broom", "callr", "caTools", "checkmate", "cli", "covr", "curl", "DBI", "digest", "dplyr", "DT", "dtplyr", "e1071", "english", "fansi", "farver", "gganimate", "gh", "hexbin", "Hmisc", "hms", "htmlTable", "ISOcodes", "knitr", "latticeExtra", "mapproj", "maptools", "mime", "mnormt", "multcomp", "mvtnorm", "ndjson", "openNLP", "pdftools", "pillar", "plyr", "prettyunits", "processx", "ps", "psych", "quantreg", "R6", "Rcpp", "RCurl", "RJSONIO", "rlang", "rmarkdown", "roxygen2", "rsconnect", "rstudioapi", "Rttf2pt1", "rversions", "scales", "selectr", "sf", "slam", "sp", "SparseM", "stringi", "svglite", "testthat", "tidyr", "tidyselect", "tinytex", "tm", "topicmodels", "TTR", "vctrs", "xaringan", "xfun", "XML", "xts", "yaml", "zoo"))
install.packages(c("BH", "broom", "callr", "caTools", "checkmate", "cli", "covr", "curl", "DBI", "digest", "dplyr", "DT", "dtplyr", "e1071", "english", "fansi", "farver", "gganimate", "gh", "hexbin", "Hmisc", "hms", "htmlTable", "ISOcodes", "knitr", "latticeExtra", "mapproj", "maptools", "mime", "mnormt", "multcomp", "mvtnorm", "ndjson", "openNLP", "pdftools", "pillar", "plyr", "prettyunits", "processx", "ps", "psych", "quantreg", "R6", "Rcpp", "RCurl", "RJSONIO", "rlang", "rmarkdown", "roxygen2", "rsconnect", "rstudioapi", "Rttf2pt1", "rversions", "scales", "selectr", "sf", "slam", "sp", "SparseM", "stringi", "svglite", "testthat", "tidyr", "tidyselect", "tinytex", "tm", "topicmodels", "TTR", "vctrs", "xaringan", "xfun", "XML", "xts", "yaml", "zoo"))
install.packages(c("BH", "boot", "broom", "callr", "cli", "curl", "DBI", "digest", "dplyr", "fansi", "farver", "foreign", "gh", "hms", "janitor", "jsonlite", "knitr", "MASS", "Matrix", "mgcv", "mime", "nlme", "pillar", "plyr", "prettyunits", "processx", "ps", "rlang", "rmarkdown", "rstudioapi", "stringi", "survival", "tidyr", "tidyselect", "tidyverse", "tinytex", "vctrs", "xfun", "yaml"))
## setup libraries
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, httr, hrbrthemes, lubridate, janitor, jsonlite, listviewer, usethis, fredr)
library(hrbrthemes)
endpoint <- "https://cmsapi.pulselive.com/rugby/rankings/mru?language=en&client=pulse"
rugby <- fromJSON(endpoint)
str(rugby)
listviewer::jsonedit(rugby, mode = "view")
head(rugby$entries$team)
rankings <-
bind_cols(
rugby$entries$team,
rugby$entries %>% select(matches:previousPos)
) %>%
clean_names() %>%
select(-c(id, alt_id, annotations)) %>% ## These columns aren't adding much of interest
select(pos, pts, everything()) %>% ## Reorder remaining columns
as_tibble() ## "Enhanced" tidyverse version of a data frame
rankings
start_date <- ymd("2004-01-01")
end_date <- floor_date(today(), unit="years")
dates <- seq(start_date, end_date, by="years")
dates <- floor_date(dates, "week", week_start = getOption("lubridate.week.start", 1))
dates
### First remove our existing variables. This is not really necessary, since R is smart enough
### to distinguish named objects in functions from named objects in our global environment.
### But I want to emphasise that we're creating new data here and avoid any confusion.
rm(rugby, rankings, endpoint)
## Now, create the function. I'll call it "rugby_scrape".
rugby_scrape <-
function(x) {
endpoint <- paste0("https://cmsapi.pulselive.com/rugby/rankings/mru?date=", x, "&client=pulse")
rugby <- fromJSON(endpoint)
rankings <-
bind_cols(
rugby$entries$team,
rugby$entries %>% select(matches:previousPos)
) %>%
clean_names() %>%
mutate(date = x) %>% ## New column to keep track of the date
select(-c(id, alt_id, annotations)) %>% ## These columns aren't adding much of interest
select(date, pos, pts, everything()) %>% ## Reorder remaining columns
as_tibble() ## "Enhanced" tidyverse version of a data frame
Sys.sleep(3) ## Be nice!
return(rankings)
}
rankings_history <-
lapply(dates, rugby_scrape) %>% ## Run the iteration
bind_rows() ## Bind the resulting list of data frames into a single data frame
rankings_history
rankings_history %>%
ggplot(aes(x=date, y=pts, group=abbreviation)) +
geom_line(col = "grey") +
geom_line(
data = rankings_history %>% filter(abbreviation %in% teams),
aes(col=fct_reorder2(abbreviation, date, pts)),
lwd = 1
) +
scale_color_manual(values = team_cols) +
labs(
x = "Date", y = "Points",
title = "International rugby rankings", caption = "Source: World Rugby"
) +
theme(legend.title = element_blank())
teams <- c("NZL", "RSA", "ENG", "JPN")
team_cols <- c("NZL"="black", "RSA"="#4DAF4A", "ENG"="#377EB8", "JPN" = "red")
rankings_history %>%
ggplot(aes(x=date, y=pts, group=abbreviation)) +
geom_line(col = "grey") +
geom_line(
data = rankings_history %>% filter(abbreviation %in% teams),
aes(col=fct_reorder2(abbreviation, date, pts)),
lwd = 1
) +
scale_color_manual(values = team_cols) +
labs(
x = "Date", y = "Points",
title = "International rugby rankings", caption = "Source: World Rugby"
) +
theme(legend.title = element_blank())
setwd("~/Dropbox/academic/projects/02_Submitted/P20_COVID-19_cities/covid-19-cities/data/phe/")
today = Sys.Date()
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv")
cases = "coronavirus-cases-latest"
write.csv(casedata, file=paste0(cases, "_", today, ".csv"))
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", sep=",")
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", sep= ",")
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", sep= " , ")
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", sep= ",")
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", sep= "," header = TRUE)
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", sep= "," row.names = TRUE)
cases = "coronavirus-cases-latest"
today = Sys.Date()
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", sep= ",", row.names = TRUE)
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", sep= ",", skipNul = TRUE)
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", sep= ",", fileEncoding = "UTF16LE")
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", sep= ",", fileEncoding = "UTF-16LE")
write.csv(casedata, file=paste0(cases, "_", today, ".csv"))
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", sep= ",", fileEncoding = "UTF-8")
write.csv(casedata, file=paste0(cases, "_", today, ".csv"))
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", sep= ",", skipNul = TRUE)
write.csv(casedata, file=paste0(cases, "_", today, ".csv"))
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", sep= ",", col.names = FALSE)
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", sep= ",", col.names = FALSE, skipNul = TRUE)
write.csv(casedata, file=paste0(cases, "_", today, ".csv"))
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", col.names = FALSE, skipNul = TRUE)
write.csv(casedata, file=paste0(cases, "_", today, ".csv"))
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", col.names = FALSE, skipNul = TRUE)
today = Sys.Date()
cases = "coronavirus-cases-latest"
casedata = read.csv("https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv", sep= ",", skipNul = TRUE)
write.csv(casedata, file=paste0(cases, "_", today, ".csv"))
